# Random Forest ë¹ ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Random Search) - ê°œì„  ë²„ì „
# 
# ê°œì„ ì‚¬í•­:
# - í–¥ìƒëœ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
# - ì—ëŸ¬ ì²˜ë¦¬ ë° ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
# - ë” ìì„¸í•œ ì¶œë ¥ ì •ë³´

import pandas as pd
import pickle
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import randint, uniform
import time
import warnings
import os
warnings.filterwarnings('ignore')

print("=== Random Forest Random Search - ê°œì„  ë²„ì „ ===\n")

# ë°ì´í„° ë¡œë“œ (í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì°¾ê¸°)
print("1. ë°ì´í„° ë¡œë“œ ì¤‘...")
try:
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì°¾ê¸°
    if os.path.exists('data/processed/df_selected_05.pkl'):
        file_path = 'data/processed/df_selected_05.pkl'
    elif os.path.exists('../data/processed/df_selected_05.pkl'):
        file_path = '../data/processed/df_selected_05.pkl'
    elif os.path.exists('df_selected_05.pkl'):
        file_path = 'df_selected_05.pkl'
    else:
        raise FileNotFoundError("df_selected_05.pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with open(file_path, 'rb') as f:
        df = pickle.load(f)
    
    print(f"âœ“ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {file_path}")
    
except Exception as e:
    print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    print(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
    print(f"ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼: {os.listdir('.')}")
    raise

# X, y ë¶„ë¦¬
print("\n2. ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
if 'SalePrice' not in df.columns:
    raise ValueError("SalePrice ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤!")
    
y = df['SalePrice']
X = df.drop('SalePrice', axis=1)

print(f"ë°ì´í„° í˜•íƒœ: X {X.shape}, y {y.shape}")
print(f"íŠ¹ì„± ëª©ë¡: {list(X.columns)}")

# êµì°¨ ê²€ì¦ ì„¤ì •
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Random Searchë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ë¶„í¬ ì •ì˜
print("\n3. íŒŒë¼ë¯¸í„° ë¶„í¬ ì„¤ì • ì¤‘...")
param_distributions = {
    'n_estimators': randint(100, 1000),           # 100~999 ì‚¬ì´ ì •ìˆ˜
    'max_depth': [None] + list(range(5, 51, 5)),  # None ë˜ëŠ” 5~50 (5 ê°„ê²©)
    'min_samples_split': randint(2, 21),          # 2~20 ì‚¬ì´ ì •ìˆ˜
    'min_samples_leaf': randint(1, 11),           # 1~10 ì‚¬ì´ ì •ìˆ˜
    'max_features': ['sqrt', 'log2'] + [0.3, 0.5, 0.7, 0.9, 1.0],  # ë‹¤ì–‘í•œ íŠ¹ì„± ë¹„ìœ¨
    'max_samples': uniform(0.6, 0.4),             # 0.6~1.0 ì‚¬ì´ ì‹¤ìˆ˜
    'bootstrap': [True, False]                     # ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‚¬ìš© ì—¬ë¶€
}

print("=== íŒŒë¼ë¯¸í„° ë¶„í¬ ===")
for param, distribution in param_distributions.items():
    print(f"{param}: {distribution}")
    
print(f"\nì´ ê°€ëŠ¥í•œ ì¡°í•©: ë§¤ìš° ë§ìŒ (ì—°ì† ë¶„í¬ í¬í•¨)")
print(f"Random Searchë¡œ 100íšŒ ì‹œë„ ì˜ˆì •")

# ê¸°ì¤€ì„  ëª¨ë¸ ì„±ëŠ¥
print("\n4. ê¸°ì¤€ì„  ëª¨ë¸ í‰ê°€ ì¤‘...")
base_model = RandomForestRegressor(random_state=42)
base_scores = cross_val_score(base_model, X, y, cv=kfold, scoring='r2')
baseline_r2 = base_scores.mean()

print(f"ê¸°ì¤€ì„  RÂ² ì ìˆ˜: {baseline_r2:.4f}")

# Random Search ì„¤ì •
print("\n5. Random Search ì‹¤í–‰ ì¤‘...")
rf = RandomForestRegressor(random_state=42, n_jobs=-1)
random_search = RandomizedSearchCV(
    rf, 
    param_distributions,
    n_iter=100,          # 100íšŒ ì‹œë„
    cv=kfold,
    scoring='r2',
    n_jobs=-1,
    verbose=1,
    random_state=42
)

print("\n=== Random Search ì‹œì‘ ===")
start_time = time.time()
random_search.fit(X, y)
end_time = time.time()

print(f"\nRandom Search ì™„ë£Œ!")
print(f"ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
print(f"ìµœì  RÂ² ì ìˆ˜: {random_search.best_score_:.4f}")
print(f"ì„±ëŠ¥ í–¥ìƒ: {random_search.best_score_ - baseline_r2:.4f}")
print(f"í–¥ìƒë¥ : {((random_search.best_score_ - baseline_r2) / baseline_r2 * 100):.2f}%")

# ìµœì  íŒŒë¼ë¯¸í„° ë¶„ì„
print("\n6. ìµœì  íŒŒë¼ë¯¸í„° ë¶„ì„ ì¤‘...")
print("=== ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ===")
best_params = random_search.best_params_
for param, value in best_params.items():
    print(f"{param}: {value}")

# ìƒìœ„ 10ê°œ ê²°ê³¼ ë¶„ì„
results_df = pd.DataFrame(random_search.cv_results_)
top_10 = results_df.nlargest(10, 'mean_test_score')[
    ['mean_test_score', 'std_test_score'] + [f'param_{p}' for p in param_distributions.keys()]
]

print("\n=== ìƒìœ„ 10ê°œ ê²°ê³¼ ===")
print(top_10.to_string(index=False))

# ìµœì¢… ëª¨ë¸ ê²€ì¦
final_model = RandomForestRegressor(**best_params, random_state=42)
final_scores = cross_val_score(final_model, X, y, cv=kfold, scoring='r2')

print(f"\n=== ìµœì¢… ê²€ì¦ ê²°ê³¼ ===")
print(f"RÂ² í‰ê· : {final_scores.mean():.4f} (Â±{final_scores.std():.4f})")
print(f"ê°œë³„ í´ë“œ ì ìˆ˜: {final_scores}")

# ëª¨ë¸ ì €ì¥
print("\n7. ëª¨ë¸ ì €ì¥ ì¤‘...")
final_model.fit(X, y)

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ê²°ì •
try:
    model_filename = 'models/quick_tuned_rf_model_fixed.pkl'
    with open(model_filename, 'wb') as f:
        pickle.dump(final_model, f)
    
    # ì €ì¥ëœ íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = os.path.getsize(model_filename) / (1024 * 1024)  # MB
    print(f"âœ“ ëª¨ë¸ì´ '{model_filename}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (íŒŒì¼ í¬ê¸°: {file_size:.1f}MB)")
    
except Exception as e:
    print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")

# íŠ¹ì„± ì¤‘ìš”ë„
print("\n8. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘...")
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': final_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\n=== íŠ¹ì„± ì¤‘ìš”ë„ (Top 5) ===")
print(feature_importance.head().to_string(index=False))

# ëª¨ë“  íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ í™•ì¸í•˜ê³  ì‹¶ì€ ê²½ìš°
print(f"\nì´ {len(feature_importance)}ê°œ íŠ¹ì„±ì˜ ì¤‘ìš”ë„ê°€ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("ì „ì²´ íŠ¹ì„± ì¤‘ìš”ë„ í•©ê³„:", feature_importance['importance'].sum())

print("\n=== ì „ì²´ íŠ¹ì„± ì¤‘ìš”ë„ ===")
for idx, row in feature_importance.iterrows():
    print(f"{row['feature']:15s}: {row['importance']:.6f}")

print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") 

